{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlcroissant as mlc\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the following 1 warning(s) during the validation:\n",
      "  -  [Metadata(F16-GVT)] Property \"https://schema.org/datePublished\" is recommended, but does not exist.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "distribution = [\n",
    "    mlc.FileObject(\n",
    "        id='F16GVT_Files.zip',\n",
    "        name='F16GVT_Files.zip',\n",
    "        description='',\n",
    "        content_url='https://data.4tu.nl/file/b6dc643b-ecc6-437c-8a8a-1681650ec3fe/5414dfdc-6e8d-4208-be6e-fa553de9866f',\n",
    "        md5='56708cabb01c39f24722d297a48891e8',\n",
    "        content_size='148455295 B',\n",
    "        encoding_format='application/zip',\n",
    "    ),\n",
    "    mlc.FileSet(\n",
    "        id='f16gvt-files',\n",
    "        name='f16gvt-files',\n",
    "        description='',\n",
    "        contained_in=['F16GVT_Files.zip'],\n",
    "        encoding_format='text/csv',\n",
    "        includes=\"F16GVT_Files/BenchmarkData/*.csv\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Add Benchmark Data\n",
    "record_sets = [\n",
    "    mlc.RecordSet(\n",
    "        id=\"force-to-acceleration\",\n",
    "        name=\"force-to-acceleration\",\n",
    "        fields=[\n",
    "            mlc.Field(\n",
    "                id=\"force-to-acceleration/force\",\n",
    "                name=\"force-to-acceleration/force\",\n",
    "                description=\"Input force\",\n",
    "                data_types=mlc.DataType.FLOAT64,\n",
    "                source=mlc.Source(\n",
    "                    file_set='f16gvt-files',\n",
    "                    extract=mlc.Extract(column=\"Force\")\n",
    "                )\n",
    "            ),\n",
    "            mlc.Field(\n",
    "                id=\"force-to-acceleration/acceleration-1\",\n",
    "                name=\"force-to-acceleration/acceleration-1\",\n",
    "                description=\"Output acceleration at position 1\",\n",
    "                data_types=mlc.DataType.FLOAT64,\n",
    "                source=mlc.Source(\n",
    "                    file_set='f16gvt-files',\n",
    "                    extract=mlc.Extract(column=\"Acceleration 1\")\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "]\n",
    "metadata = mlc.Metadata(\n",
    "    name='F16-GVT',\n",
    "    description='Ground vibration data of a F16 wing.',\n",
    "    cite_as=\"@misc{https://doi.org/10.4121/12954911.v1, doi = {10.4121/12954911.v1}, url = {https://data.4tu.nl/articles/dataset/F-16_Aircraft_Benchmark_Based_on_Ground_Vibration_Test_Data/12954911/1}, author = {NoÃ«l, Jean-Philippe and Schoukens, Maarten},keywords = {Ground Vibration Test, System Identification, Nonlinear System, Dynamical System, Time Series, Machine Learning},title = {F-16 Aircraft Benchmark Based on Ground Vibration Test Data}, publisher = {4TU.ResearchData},year = {2020},copyright = {CC BY-SA 4.0},}\",\n",
    "    url=\"https://data.4tu.nl/articles/_/12954911\",\n",
    "    distribution=distribution,\n",
    "    record_sets=record_sets,\n",
    "    # date_published='2020-09-21',\n",
    "    version='0.0.1',\n",
    "    license='https://spdx.org/licenses/CC-BY-4.0.html'\n",
    ")\n",
    "print(metadata.issues.report())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"./schema/f16-croissant.json\", \"w\") as f:\n",
    "    content = metadata.to_json()\n",
    "    content = json.dumps(content, indent=2)\n",
    "    f.write(content)\n",
    "    f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found the following 1 warning(s) during the validation:\n",
      "  -  [Metadata(F16-GVT)] Property \"https://schema.org/datePublished\" is recommended, but does not exist.\n"
     ]
    },
    {
     "ename": "GenerationError",
     "evalue": "An error occured during the streaming generation of the dataset, more specifically during the operation ReadFields(force-to-acceleration)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/mlcroissant/_src/operation_graph/execute.py:97\u001b[0m, in \u001b[0;36mexecute_operations_in_streaming\u001b[0;34m(record_set, operations, list_of_operations, result)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m operation\u001b[38;5;241m.\u001b[39mcall(result)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/mlcroissant/_src/operation_graph/operations/field.py:257\u001b[0m, in \u001b[0;36mReadFields.call\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df), chunk_size):\n\u001b[0;32m--> 257\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_get_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/pandas/core/frame.py:9568\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9559\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m   9560\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   9561\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9566\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m   9567\u001b[0m )\n\u001b[0;32m-> 9568\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/pandas/core/apply.py:764\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[0;32m--> 764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/pandas/core/apply.py:891\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 891\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/pandas/core/apply.py:907\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 907\u001b[0m     results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    909\u001b[0m         \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/mlcroissant/_src/operation_graph/operations/field.py:219\u001b[0m, in \u001b[0;36mReadFields.call.<locals>._get_result\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m    218\u001b[0m column \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mget_column()\n\u001b[0;32m--> 219\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m df, (\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumn \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m does not exist. Inspect the ancestors of the\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m field \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfield\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to understand why. Possible fields: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    222\u001b[0m )\n\u001b[1;32m    223\u001b[0m is_repeated \u001b[38;5;241m=\u001b[39m field\u001b[38;5;241m.\u001b[39mrepeated \u001b[38;5;129;01mor\u001b[39;00m _is_repeated_field(field\u001b[38;5;241m.\u001b[39mparent)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Column \"Force\" does not exist. Inspect the ancestors of the field Field(uuid=\"force-to-acceleration/force\") to understand why. Possible fields: Int64Index([3, 2, 4], dtype='int64')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mGenerationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m mlc\u001b[38;5;241m.\u001b[39mDataset(jsonld\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./schema/f16-croissant.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m records \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mrecords(record_set\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforce-to-acceleration\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrecords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# for i, record in enumerate(records):\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#     print(record)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/mlcroissant/_src/datasets.py:166\u001b[0m, in \u001b[0;36mRecords.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# We can stream the dataset iff the operation graph is a path graph (meaning\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# that all operations lie on a single straight line, i.e. have an\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m# in-degree of 0 or 1. That means that the operation graph is a single line\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# (without external joins for example).\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_streamable_dataset(operations):\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m execute_operations_in_streaming(\n\u001b[1;32m    167\u001b[0m         record_set\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord_set,\n\u001b[1;32m    168\u001b[0m         operations\u001b[38;5;241m=\u001b[39moperations,\n\u001b[1;32m    169\u001b[0m     )\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m execute_operations_sequentially(\n\u001b[1;32m    172\u001b[0m         record_set\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord_set, operations\u001b[38;5;241m=\u001b[39moperations\n\u001b[1;32m    173\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/mlcroissant/_src/operation_graph/execute.py:121\u001b[0m, in \u001b[0;36mexecute_operations_in_streaming\u001b[0;34m(record_set, operations, list_of_operations, result)\u001b[0m\n\u001b[1;32m    119\u001b[0m         result \u001b[38;5;241m=\u001b[39m operation\u001b[38;5;241m.\u001b[39mcall(result)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GenerationError(\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occured during the streaming generation of the dataset, more\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m specifically during the operation \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moperation\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mGenerationError\u001b[0m: An error occured during the streaming generation of the dataset, more specifically during the operation ReadFields(force-to-acceleration)"
     ]
    }
   ],
   "source": [
    "dataset = mlc.Dataset(jsonld='./schema/f16-croissant.json')\n",
    "records = dataset.records(record_set='force-to-acceleration')\n",
    "\n",
    "list(records)\n",
    "\n",
    "# for i, record in enumerate(records):\n",
    "#     print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow_datasets as tfds\n",
    "data_dir = './data'\n",
    "local_croissant_file = './schema/f16-croissant.json'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:WARNING: The JSON-LD `@context` is not standard. Refer to the official @context (e.g., from the example datasets in https://github.com/mlcommons/croissant/tree/main/datasets/1.0). The different keys are: {'cr', 'transform', '@language', 'field', 'recordSet', 'separator', 'isLiveDataset', '@vocab', 'fileSet', 'rai', 'extract', 'source', 'citeAs', 'path', 'data', 'fileProperty', 'dataType', 'regex', 'format', 'fileObject', 'md5', 'repeated', 'examples', 'parentField', 'dct', 'column', 'jsonPath', 'key', 'includes', 'sc', 'references', 'subField', 'conformsTo', 'replace'}\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "Found the following 1 error(s) during the validation:\n  -  The current JSON-LD doesn't extend https://schema.org/Dataset.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m test_croissant_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./schema/test.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m builder \u001b[38;5;241m=\u001b[39m \u001b[43mtfds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_builders\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCroissantBuilder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjsonld\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_croissant_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrecord_set_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexamples\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/tensorflow_datasets/core/dataset_builders/croissant_builder.py:278\u001b[0m, in \u001b[0;36mCroissantBuilder.__init__\u001b[0;34m(self, jsonld, record_set_ids, disable_shuffling, int_dtype, float_dtype, mapping, overwrite_version, filters, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjsonld \u001b[38;5;241m=\u001b[39m jsonld\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmapping \u001b[38;5;241m=\u001b[39m mapping\n\u001b[0;32m--> 278\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mmlc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjsonld\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmapping\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m croissant_utils\u001b[38;5;241m.\u001b[39mget_tfds_dataset_name(dataset)\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mmetadata\n",
      "File \u001b[0;32m<string>:6\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, jsonld, debug, mapping)\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/mlcroissant/_src/datasets.py:89\u001b[0m, in \u001b[0;36mDataset.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m Metadata\u001b[38;5;241m.\u001b[39mfrom_json(ctx\u001b[38;5;241m=\u001b[39mctx, json_\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjsonld)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjsonld \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m \u001b[43mMetadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjsonld\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/mlcroissant/_src/structure_graph/nodes/metadata.py:441\u001b[0m, in \u001b[0;36mMetadata.from_file\u001b[0;34m(cls, ctx, file)\u001b[0m\n\u001b[1;32m    439\u001b[0m folder, json_ \u001b[38;5;241m=\u001b[39m from_file_to_json(file)\n\u001b[1;32m    440\u001b[0m ctx\u001b[38;5;241m.\u001b[39mfolder \u001b[38;5;241m=\u001b[39m folder\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/mlcroissant/_src/structure_graph/nodes/metadata.py:451\u001b[0m, in \u001b[0;36mMetadata.from_json\u001b[0;34m(cls, ctx, json_)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a `Metadata` from JSON.\"\"\"\u001b[39;00m\n\u001b[1;32m    450\u001b[0m ctx\u001b[38;5;241m.\u001b[39mrdf \u001b[38;5;241m=\u001b[39m Rdf\u001b[38;5;241m.\u001b[39mfrom_json(ctx, json_)\n\u001b[0;32m--> 451\u001b[0m jsonld \u001b[38;5;241m=\u001b[39m \u001b[43mexpand_jsonld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_jsonld(ctx\u001b[38;5;241m=\u001b[39mctx, jsonld\u001b[38;5;241m=\u001b[39mjsonld)\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/mlcroissant/_src/core/json_ld.py:224\u001b[0m, in \u001b[0;36mexpand_jsonld\u001b[0;34m(data, ctx)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m entry_node \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m     ctx\u001b[38;5;241m.\u001b[39missues\u001b[38;5;241m.\u001b[39madd_error(\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe current JSON-LD doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt extend https://schema.org/Dataset.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    223\u001b[0m     )\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ValidationError(ctx\u001b[38;5;241m.\u001b[39missues\u001b[38;5;241m.\u001b[39mreport())\n\u001b[1;32m    225\u001b[0m id_to_node: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Json] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes:\n",
      "\u001b[0;31mValidationError\u001b[0m: Found the following 1 error(s) during the validation:\n  -  The current JSON-LD doesn't extend https://schema.org/Dataset."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "test_croissant_file = './schema/test.json'\n",
    "builder = tfds.core.dataset_builders.CroissantBuilder(\n",
    "    jsonld=test_croissant_file,\n",
    "    record_set_ids=['examples'],\n",
    "    data_dir=data_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found the following 1 warning(s) during the validation:\n",
      "  -  [Metadata(F16-GVT)] Property \"https://schema.org/datePublished\" is recommended, but does not exist.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "builder = tfds.core.dataset_builders.CroissantBuilder(\n",
    "    jsonld=local_croissant_file,\n",
    "    record_set_ids=['force-to-acceleration'],\n",
    "    data_dir=data_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found the following 1 warning(s) during the validation:\n",
      "  -  [Metadata(F16-GVT)] Property \"https://schema.org/datePublished\" is recommended, but does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to data/f16_gvt/force_to_acceleration/0.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e18620730a8b455795f8c4cdc12036de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/1 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'apache_beam.transforms.combiners._TopPerBundle'>)\n",
      "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'tensorflow_datasets.core.writer.BeamWriter'>)\n",
      "ERROR:apache_beam.runners.common:'Path' object is not iterable [while running 'default/no filter f16gvt-files: pass the index to the next operation.']\n",
      "Traceback (most recent call last):\n",
      "  File \"apache_beam/runners/common.py\", line 1501, in apache_beam.runners.common.DoFnRunner.process\n",
      "  File \"apache_beam/runners/common.py\", line 690, in apache_beam.runners.common.SimpleInvoker.invoke_process\n",
      "  File \"/Users/jack/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/transforms/core.py\", line 2161, in <lambda>\n",
      "    wrapper = lambda x: [fn(*x)]\n",
      "                         ^^^^^^\n",
      "  File \"/Users/jack/Documents/python_venv/crnn/lib/python3.12/site-packages/mlcroissant/_src/operation_graph/execute.py\", line 238, in _pass_index\n",
      "    return (index, operation.call(element))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jack/Documents/python_venv/crnn/lib/python3.12/site-packages/mlcroissant/_src/operation_graph/operations/concatenate.py\", line 23, in call\n",
      "    files = [file for files in args for file in files]\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: 'Path' object is not iterable\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Path' object is not iterable [while running 'default/no filter f16gvt-files: pass the index to the next operation.']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/common.py:1501\u001b[0m, in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/common.py:690\u001b[0m, in \u001b[0;36mapache_beam.runners.common.SimpleInvoker.invoke_process\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/transforms/core.py:2161\u001b[0m, in \u001b[0;36mMapTuple.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   2160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2161\u001b[0m   wrapper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: [\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m   2163\u001b[0m \u001b[38;5;66;03m# Proxy the type-hint information from the original function to this new\u001b[39;00m\n\u001b[1;32m   2164\u001b[0m \u001b[38;5;66;03m# wrapped function.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/mlcroissant/_src/operation_graph/execute.py:238\u001b[0m, in \u001b[0;36m_pass_index\u001b[0;34m(index, element, operation)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Passes the index to the next operation while executing the operation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (index, \u001b[43moperation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/mlcroissant/_src/operation_graph/operations/concatenate.py:23\u001b[0m, in \u001b[0;36mConcatenate.call\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo dataframe to merge.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 23\u001b[0m files \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m     25\u001b[0m     FileProperty\u001b[38;5;241m.\u001b[39mfilepath: [os\u001b[38;5;241m.\u001b[39mfspath(file\u001b[38;5;241m.\u001b[39mfilepath) \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files],\n\u001b[1;32m     26\u001b[0m     FileProperty\u001b[38;5;241m.\u001b[39mfilename: [file\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files],\n\u001b[1;32m     27\u001b[0m     FileProperty\u001b[38;5;241m.\u001b[39mfullpath: [os\u001b[38;5;241m.\u001b[39mfspath(file\u001b[38;5;241m.\u001b[39mfullpath) \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files],\n\u001b[1;32m     28\u001b[0m })\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Path' object is not iterable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m beam_options \u001b[38;5;241m=\u001b[39m PipelineOptions(\n\u001b[1;32m      4\u001b[0m     flags \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m download_config \u001b[38;5;241m=\u001b[39m tfds\u001b[38;5;241m.\u001b[39mdownload\u001b[38;5;241m.\u001b[39mDownloadConfig(beam_options\u001b[38;5;241m=\u001b[39mbeam_options)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_and_prepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/tensorflow_datasets/core/logging/__init__.py:176\u001b[0m, in \u001b[0;36m_FunctionDecorator.__call__\u001b[0;34m(self, function, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_call()\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m   metadata\u001b[38;5;241m.\u001b[39mmark_error()\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/tensorflow_datasets/core/dataset_builder.py:763\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[0;34m(self, download_dir, download_config, file_format, permissions)\u001b[0m\n\u001b[1;32m    761\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mread_from_directory(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_dir)\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 763\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    764\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    766\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    768\u001b[0m   \u001b[38;5;66;03m# NOTE: If modifying the lines below to put additional information in\u001b[39;00m\n\u001b[1;32m    769\u001b[0m   \u001b[38;5;66;03m# DatasetInfo, you'll likely also want to update\u001b[39;00m\n\u001b[1;32m    770\u001b[0m   \u001b[38;5;66;03m# DatasetInfo.read_from_directory to possibly restore these attributes\u001b[39;00m\n\u001b[1;32m    771\u001b[0m   \u001b[38;5;66;03m# when reading from package data.\u001b[39;00m\n\u001b[1;32m    772\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdownload_size \u001b[38;5;241m=\u001b[39m dl_manager\u001b[38;5;241m.\u001b[39mdownloaded_size\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/tensorflow_datasets/core/dataset_builder.py:1808\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, download_config)\u001b[0m\n\u001b[1;32m   1805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download_config\u001b[38;5;241m.\u001b[39mmax_examples_per_split \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1806\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m-> 1808\u001b[0m split_infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_splits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1810\u001b[0m \u001b[38;5;66;03m# Update the info object with the splits.\u001b[39;00m\n\u001b[1;32m   1811\u001b[0m split_dict \u001b[38;5;241m=\u001b[39m splits_lib\u001b[38;5;241m.\u001b[39mSplitDict(split_infos)\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/tensorflow_datasets/core/dataset_builder.py:1746\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._generate_splits\u001b[0;34m(self, dl_manager, download_config)\u001b[0m\n\u001b[1;32m   1728\u001b[0m split_builder \u001b[38;5;241m=\u001b[39m split_builder_lib\u001b[38;5;241m.\u001b[39mSplitBuilder(\n\u001b[1;32m   1729\u001b[0m     split_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39msplits,\n\u001b[1;32m   1730\u001b[0m     features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mfeatures,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     ignore_duplicates\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mignore_duplicates,\n\u001b[1;32m   1738\u001b[0m )\n\u001b[1;32m   1739\u001b[0m \u001b[38;5;66;03m# Wrap the generation inside a context manager.\u001b[39;00m\n\u001b[1;32m   1740\u001b[0m \u001b[38;5;66;03m# If `beam` is used during generation (when a pipeline gets created),\u001b[39;00m\n\u001b[1;32m   1741\u001b[0m \u001b[38;5;66;03m# the context manager is equivalent to `with beam.Pipeline()`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;66;03m# to go from non-beam to beam dataset:\u001b[39;00m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# https://www.tensorflow.org/datasets/beam_datasets#instructions\u001b[39;00m\n\u001b[0;32m-> 1746\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msplit_builder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_beam_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmaybe_pipeline_proxy\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1747\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# If the signature has a `pipeline` kwargs, create the pipeline now and\u001b[39;49;00m\n\u001b[1;32m   1748\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# forward it to `self._split_generators`\u001b[39;49;00m\n\u001b[1;32m   1749\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# We add this magic because the pipeline kwargs is only used by c4 and\u001b[39;49;00m\n\u001b[1;32m   1750\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# we do not want to make the API more verbose for a single advanced case.\u001b[39;49;00m\n\u001b[1;32m   1751\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# See also the documentation at the end here:\u001b[39;49;00m\n\u001b[1;32m   1752\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# https://www.tensorflow.org/datasets/api_docs/python/tfds/core/GeneratorBasedBuilder?version=nightly#_generate_examples\u001b[39;49;00m\n\u001b[1;32m   1753\u001b[0m \u001b[43m  \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_split_generators\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1754\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py:144\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/tensorflow_datasets/core/split_builder.py:305\u001b[0m, in \u001b[0;36mSplitBuilder.maybe_beam_pipeline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m   \u001b[38;5;66;03m# If the Beam pipeline was used, then exit it.\u001b[39;00m\n\u001b[1;32m    304\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_beam_pipeline \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_beam_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__exit__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;66;03m# Fill in the beam pipeline in the proxy.\u001b[39;00m\n\u001b[1;32m    307\u001b[0m     pipeline_proxy\u001b[38;5;241m.\u001b[39m_beam_pipeline \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_beam_pipeline  \u001b[38;5;66;03m# pylint:disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/pipeline.py:644\u001b[0m, in \u001b[0;36mPipeline.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    643\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exc_type:\n\u001b[0;32m--> 644\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    645\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options\u001b[38;5;241m.\u001b[39mview_as(StandardOptions)\u001b[38;5;241m.\u001b[39mno_wait_until_finish:\n\u001b[1;32m    646\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult\u001b[38;5;241m.\u001b[39mwait_until_finish()\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/pipeline.py:618\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self, test_runner_api)\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    617\u001b[0m       shutil\u001b[38;5;241m.\u001b[39mrmtree(tmpdir)\n\u001b[0;32m--> 618\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    620\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_in_ipython():\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/direct/direct_runner.py:184\u001b[0m, in \u001b[0;36mSwitchingDirectRunner.run_pipeline\u001b[0;34m(self, pipeline, options)\u001b[0m\n\u001b[1;32m    181\u001b[0m     _LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFalling back to DirectRunner\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    182\u001b[0m     runner \u001b[38;5;241m=\u001b[39m BundleBasedDirectRunner()\n\u001b[0;32m--> 184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py:195\u001b[0m, in \u001b[0;36mFnApiRunner.run_pipeline\u001b[0;34m(self, pipeline, options)\u001b[0m\n\u001b[1;32m    184\u001b[0m   _LOGGER\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    185\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf direct_num_workers is not equal to 1, direct_running_mode \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    186\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshould be `multi_processing` or `multi_threading` instead of \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    189\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_workers,\n\u001b[1;32m    190\u001b[0m       running_mode)\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profiler_factory \u001b[38;5;241m=\u001b[39m Profile\u001b[38;5;241m.\u001b[39mfactory_from_options(\n\u001b[1;32m    193\u001b[0m     options\u001b[38;5;241m.\u001b[39mview_as(pipeline_options\u001b[38;5;241m.\u001b[39mProfilingOptions))\n\u001b[0;32m--> 195\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_latest_run_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_via_runner_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_runner_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdefault_environment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_default_environment\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_latest_run_result\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py:221\u001b[0m, in \u001b[0;36mFnApiRunner.run_via_runner_api\u001b[0;34m(self, pipeline_proto, options)\u001b[0m\n\u001b[1;32m    218\u001b[0m pipeline_proto \u001b[38;5;241m=\u001b[39m merge_common_environments(\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_any_environments(pipeline_proto))\n\u001b[1;32m    220\u001b[0m stage_context, stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_stages(pipeline_proto)\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_stages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstage_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstages\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py:468\u001b[0m, in \u001b[0;36mFnApiRunner.run_stages\u001b[0;34m(self, stage_context, stages)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m consuming_stage_name \u001b[38;5;241m==\u001b[39m bundle_context_manager\u001b[38;5;241m.\u001b[39mstage\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    467\u001b[0m bundle_counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 468\u001b[0m bundle_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_bundle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunner_execution_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbundle_context_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbundle_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m consuming_stage_name \u001b[38;5;129;01min\u001b[39;00m monitoring_infos_by_stage:\n\u001b[1;32m    472\u001b[0m   monitoring_infos_by_stage[\n\u001b[1;32m    473\u001b[0m       consuming_stage_name] \u001b[38;5;241m=\u001b[39m consolidate_monitoring_infos(\n\u001b[1;32m    474\u001b[0m           itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    475\u001b[0m               bundle_results\u001b[38;5;241m.\u001b[39mprocess_bundle\u001b[38;5;241m.\u001b[39mmonitoring_infos,\n\u001b[1;32m    476\u001b[0m               monitoring_infos_by_stage[consuming_stage_name]))\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py:793\u001b[0m, in \u001b[0;36mFnApiRunner._execute_bundle\u001b[0;34m(self, runner_execution_context, bundle_context_manager, bundle_input)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# We create the bundle manager here, as it can be reused for bundles of\u001b[39;00m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;66;03m# the same stage, but it may have to be created by-bundle later on.\u001b[39;00m\n\u001b[1;32m    790\u001b[0m bundle_manager \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_bundle_manager(bundle_context_manager)\n\u001b[1;32m    792\u001b[0m last_result, deferred_inputs, newly_set_timers, watermark_updates \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 793\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_bundle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrunner_execution_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbundle_context_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbundle_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbundle_context_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstage_data_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbundle_context_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstage_timer_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbundle_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pc_name, watermark \u001b[38;5;129;01min\u001b[39;00m watermark_updates\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    802\u001b[0m   _BUNDLE_LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUpdate: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m, pc_name, watermark)\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py:1032\u001b[0m, in \u001b[0;36mFnApiRunner._run_bundle\u001b[0;34m(self, runner_execution_context, bundle_context_manager, bundle_input, data_output, expected_timer_output, bundle_manager)\u001b[0m\n\u001b[1;32m   1023\u001b[0m input_timers \u001b[38;5;241m=\u001b[39m bundle_input\u001b[38;5;241m.\u001b[39mtimers\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_bundle_multiple_times_for_testing(\n\u001b[1;32m   1025\u001b[0m     runner_execution_context,\n\u001b[1;32m   1026\u001b[0m     bundle_manager,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1029\u001b[0m     input_timers,\n\u001b[1;32m   1030\u001b[0m     expected_timer_output)\n\u001b[0;32m-> 1032\u001b[0m result, splits \u001b[38;5;241m=\u001b[39m \u001b[43mbundle_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_bundle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_timers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected_timer_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;66;03m# Now we collect all the deferred inputs remaining from bundle execution.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;66;03m# Deferred inputs can be:\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;66;03m# - timers\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;66;03m# - SDK-initiated deferred applications of root elements\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;66;03m# - Runner-initiated deferred applications of root elements\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m deferred_inputs: Dict[\u001b[38;5;28mstr\u001b[39m, execution\u001b[38;5;241m.\u001b[39mPartitionableBuffer] \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py:1358\u001b[0m, in \u001b[0;36mBundleManager.process_bundle\u001b[0;34m(self, inputs, expected_outputs, fired_timers, expected_output_timers, dry_run)\u001b[0m\n\u001b[1;32m   1351\u001b[0m \u001b[38;5;66;03m# Actually start the bundle.\u001b[39;00m\n\u001b[1;32m   1352\u001b[0m process_bundle_req \u001b[38;5;241m=\u001b[39m beam_fn_api_pb2\u001b[38;5;241m.\u001b[39mInstructionRequest(\n\u001b[1;32m   1353\u001b[0m     instruction_id\u001b[38;5;241m=\u001b[39mprocess_bundle_id,\n\u001b[1;32m   1354\u001b[0m     process_bundle\u001b[38;5;241m=\u001b[39mbeam_fn_api_pb2\u001b[38;5;241m.\u001b[39mProcessBundleRequest(\n\u001b[1;32m   1355\u001b[0m         process_bundle_descriptor_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbundle_context_manager\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m   1356\u001b[0m         process_bundle_descriptor\u001b[38;5;241m.\u001b[39mid,\n\u001b[1;32m   1357\u001b[0m         cache_tokens\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache_token_generator)]))\n\u001b[0;32m-> 1358\u001b[0m result_future \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_worker_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontrol_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_bundle_req\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1360\u001b[0m split_results: List[beam_fn_api_pb2\u001b[38;5;241m.\u001b[39mProcessBundleSplitResponse] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1361\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ProgressRequester(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_worker_handler,\n\u001b[1;32m   1362\u001b[0m                        process_bundle_id,\n\u001b[1;32m   1363\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_progress_frequency):\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/portability/fn_api_runner/worker_handlers.py:386\u001b[0m, in \u001b[0;36mEmbeddedWorkerHandler.push\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    384\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_uid_counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    385\u001b[0m   request\u001b[38;5;241m.\u001b[39minstruction_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontrol_\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_uid_counter\n\u001b[0;32m--> 386\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_instruction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ControlFuture(request\u001b[38;5;241m.\u001b[39minstruction_id, response)\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/worker/sdk_worker.py:658\u001b[0m, in \u001b[0;36mSdkWorker.do_instruction\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    655\u001b[0m request_type \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mWhichOneof(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request_type:\n\u001b[1;32m    657\u001b[0m   \u001b[38;5;66;03m# E.g. if register is set, this will call self.register(request.register))\u001b[39;00m\n\u001b[0;32m--> 658\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstruction_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    661\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/worker/sdk_worker.py:696\u001b[0m, in \u001b[0;36mSdkWorker.process_bundle\u001b[0;34m(self, request, instruction_id)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m bundle_processor\u001b[38;5;241m.\u001b[39mstate_handler\u001b[38;5;241m.\u001b[39mprocess_instruction_id(\n\u001b[1;32m    693\u001b[0m     instruction_id, request\u001b[38;5;241m.\u001b[39mcache_tokens):\n\u001b[1;32m    694\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaybe_profile(instruction_id):\n\u001b[1;32m    695\u001b[0m     delayed_applications, requests_finalization \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 696\u001b[0m         \u001b[43mbundle_processor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_bundle\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstruction_id\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    697\u001b[0m     monitoring_infos \u001b[38;5;241m=\u001b[39m bundle_processor\u001b[38;5;241m.\u001b[39mmonitoring_infos()\n\u001b[1;32m    698\u001b[0m     response \u001b[38;5;241m=\u001b[39m beam_fn_api_pb2\u001b[38;5;241m.\u001b[39mInstructionResponse(\n\u001b[1;32m    699\u001b[0m         instruction_id\u001b[38;5;241m=\u001b[39minstruction_id,\n\u001b[1;32m    700\u001b[0m         process_bundle\u001b[38;5;241m=\u001b[39mbeam_fn_api_pb2\u001b[38;5;241m.\u001b[39mProcessBundleResponse(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    706\u001b[0m             },\n\u001b[1;32m    707\u001b[0m             requires_finalization\u001b[38;5;241m=\u001b[39mrequests_finalization))\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/worker/bundle_processor.py:1274\u001b[0m, in \u001b[0;36mBundleProcessor.process_bundle\u001b[0;34m(self, instruction_id)\u001b[0m\n\u001b[1;32m   1271\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mops[element\u001b[38;5;241m.\u001b[39mtransform_id]\u001b[38;5;241m.\u001b[39mprocess_timer(\n\u001b[1;32m   1272\u001b[0m         element\u001b[38;5;241m.\u001b[39mtimer_family_id, timer_data)\n\u001b[1;32m   1273\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(element, beam_fn_api_pb2\u001b[38;5;241m.\u001b[39mElements\u001b[38;5;241m.\u001b[39mData):\n\u001b[0;32m-> 1274\u001b[0m   \u001b[43minput_op_by_transform_id\u001b[49m\u001b[43m[\u001b[49m\u001b[43melement\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_id\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_encoded\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[43m      \u001b[49m\u001b[43melement\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[38;5;66;03m# We are done consuming the set of elements.\u001b[39;00m\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconsuming_received_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/worker/bundle_processor.py:237\u001b[0m, in \u001b[0;36mDataInputOperation.process_encoded\u001b[0;34m(self, encoded_windowed_values)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exn:\n\u001b[1;32m    234\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    235\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError decoding input stream with coder \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    236\u001b[0m       \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindowed_coder)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexn\u001b[39;00m\n\u001b[0;32m--> 237\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded_value\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/worker/operations.py:567\u001b[0m, in \u001b[0;36mapache_beam.runners.worker.operations.Operation.output\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/worker/operations.py:569\u001b[0m, in \u001b[0;36mapache_beam.runners.worker.operations.Operation.output\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/worker/operations.py:260\u001b[0m, in \u001b[0;36mapache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/worker/operations.py:263\u001b[0m, in \u001b[0;36mapache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/worker/operations.py:950\u001b[0m, in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/worker/operations.py:951\u001b[0m, in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/common.py:1503\u001b[0m, in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/common.py:1591\u001b[0m, in \u001b[0;36mapache_beam.runners.common.DoFnRunner._reraise_augmented\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/common.py:1501\u001b[0m, in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/common.py:689\u001b[0m, in \u001b[0;36mapache_beam.runners.common.SimpleInvoker.invoke_process\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/common.py:1686\u001b[0m, in \u001b[0;36mapache_beam.runners.common._OutputHandler.handle_process_outputs\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/common.py:1799\u001b[0m, in \u001b[0;36mapache_beam.runners.common._OutputHandler._write_value_to_tag\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/worker/operations.py:263\u001b[0m, in \u001b[0;36mapache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/worker/operations.py:950\u001b[0m, in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/worker/operations.py:951\u001b[0m, in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/common.py:1503\u001b[0m, in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/common.py:1591\u001b[0m, in \u001b[0;36mapache_beam.runners.common.DoFnRunner._reraise_augmented\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/common.py:1501\u001b[0m, in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/common.py:689\u001b[0m, in \u001b[0;36mapache_beam.runners.common.SimpleInvoker.invoke_process\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/common.py:1686\u001b[0m, in \u001b[0;36mapache_beam.runners.common._OutputHandler.handle_process_outputs\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/common.py:1799\u001b[0m, in \u001b[0;36mapache_beam.runners.common._OutputHandler._write_value_to_tag\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/worker/operations.py:263\u001b[0m, in \u001b[0;36mapache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/worker/operations.py:950\u001b[0m, in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/worker/operations.py:951\u001b[0m, in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/common.py:1503\u001b[0m, in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/common.py:1591\u001b[0m, in \u001b[0;36mapache_beam.runners.common.DoFnRunner._reraise_augmented\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/common.py:1501\u001b[0m, in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/common.py:689\u001b[0m, in \u001b[0;36mapache_beam.runners.common.SimpleInvoker.invoke_process\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/common.py:1686\u001b[0m, in \u001b[0;36mapache_beam.runners.common._OutputHandler.handle_process_outputs\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/common.py:1799\u001b[0m, in \u001b[0;36mapache_beam.runners.common._OutputHandler._write_value_to_tag\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/worker/operations.py:263\u001b[0m, in \u001b[0;36mapache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/worker/operations.py:950\u001b[0m, in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/worker/operations.py:951\u001b[0m, in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/common.py:1503\u001b[0m, in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/common.py:1612\u001b[0m, in \u001b[0;36mapache_beam.runners.common.DoFnRunner._reraise_augmented\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/common.py:1501\u001b[0m, in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/runners/common.py:690\u001b[0m, in \u001b[0;36mapache_beam.runners.common.SimpleInvoker.invoke_process\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/apache_beam/transforms/core.py:2161\u001b[0m, in \u001b[0;36mMapTuple.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   2159\u001b[0m   wrapper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: [fn(\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mtuple\u001b[39m(x) \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   2160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2161\u001b[0m   wrapper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: [\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m   2163\u001b[0m \u001b[38;5;66;03m# Proxy the type-hint information from the original function to this new\u001b[39;00m\n\u001b[1;32m   2164\u001b[0m \u001b[38;5;66;03m# wrapped function.\u001b[39;00m\n\u001b[1;32m   2165\u001b[0m type_hints \u001b[38;5;241m=\u001b[39m get_type_hints(fn)\u001b[38;5;241m.\u001b[39mwith_defaults(\n\u001b[1;32m   2166\u001b[0m     typehints\u001b[38;5;241m.\u001b[39mdecorators\u001b[38;5;241m.\u001b[39mIOTypeHints\u001b[38;5;241m.\u001b[39mfrom_callable(fn))\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/mlcroissant/_src/operation_graph/execute.py:238\u001b[0m, in \u001b[0;36m_pass_index\u001b[0;34m(index, element, operation)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pass_index\u001b[39m(index: \u001b[38;5;28mint\u001b[39m, element: Any, operation: Operation) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ElementWithIndex:\n\u001b[1;32m    237\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Passes the index to the next operation while executing the operation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (index, \u001b[43moperation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Documents/python_venv/crnn/lib/python3.12/site-packages/mlcroissant/_src/operation_graph/operations/concatenate.py:23\u001b[0m, in \u001b[0;36mConcatenate.call\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See class' docstring.\"\"\"\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo dataframe to merge.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 23\u001b[0m files \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m     25\u001b[0m     FileProperty\u001b[38;5;241m.\u001b[39mfilepath: [os\u001b[38;5;241m.\u001b[39mfspath(file\u001b[38;5;241m.\u001b[39mfilepath) \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files],\n\u001b[1;32m     26\u001b[0m     FileProperty\u001b[38;5;241m.\u001b[39mfilename: [file\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files],\n\u001b[1;32m     27\u001b[0m     FileProperty\u001b[38;5;241m.\u001b[39mfullpath: [os\u001b[38;5;241m.\u001b[39mfspath(file\u001b[38;5;241m.\u001b[39mfullpath) \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files],\n\u001b[1;32m     28\u001b[0m })\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Path' object is not iterable [while running 'default/no filter f16gvt-files: pass the index to the next operation.']"
     ]
    }
   ],
   "source": [
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "\n",
    "beam_options = PipelineOptions(\n",
    "    flags = []\n",
    ")\n",
    "download_config = tfds.download.DownloadConfig(beam_options=beam_options)\n",
    "builder.download_and_prepare(download_config=download_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:67: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:67: SyntaxWarning: invalid escape sequence '\\.'\n",
      "/var/folders/20/k44l3vsj03x1v_37v25mlp4w0000gn/T/ipykernel_56250/4178762222.py:67: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  transforms=[mlc.Transform(regex=\"^(.*)\\.jsonl$\")],\n"
     ]
    }
   ],
   "source": [
    "import mlcroissant as mlc\n",
    "\n",
    "# FileObjects and FileSets define the resources of the dataset.\n",
    "distribution = [\n",
    "    # gpt-3 is hosted on a GitHub repository:\n",
    "    mlc.FileObject(\n",
    "        id=\"github-repository\",\n",
    "        name=\"github-repository\",\n",
    "        description=\"OpenAI repository on GitHub.\",\n",
    "        content_url=\"https://github.com/openai/gpt-3\",\n",
    "        encoding_format=\"git+https\",\n",
    "        sha256=\"main\",\n",
    "    ),\n",
    "    # Within that repository, a FileSet lists all JSONL files:\n",
    "    mlc.FileSet(\n",
    "        id=\"jsonl-files\",\n",
    "        name=\"jsonl-files\",\n",
    "        description=\"JSONL files are hosted on the GitHub repository.\",\n",
    "        contained_in=[\"github-repository\"],\n",
    "        encoding_format=\"application/jsonlines\",\n",
    "        includes=\"data/*.jsonl\",\n",
    "    ),\n",
    "]\n",
    "record_sets = [\n",
    "    # RecordSets contains records in the dataset.\n",
    "    mlc.RecordSet(\n",
    "        id=\"jsonl\",\n",
    "        name=\"jsonl\",\n",
    "        # Each record has one or many fields...\n",
    "        fields=[\n",
    "            # Fields can be extracted from the FileObjects/FileSets.\n",
    "            mlc.Field(\n",
    "                id=\"jsonl/context\",\n",
    "                name=\"context\",\n",
    "                description=\"\",\n",
    "                data_types=mlc.DataType.TEXT,\n",
    "                source=mlc.Source(\n",
    "                    file_set=\"jsonl-files\",\n",
    "                    # Extract the field from the column of a FileObject/FileSet:\n",
    "                    extract=mlc.Extract(column=\"context\"),\n",
    "                ),\n",
    "            ),\n",
    "            mlc.Field(\n",
    "                id=\"jsonl/completion\",\n",
    "                name=\"completion\",\n",
    "                description=\"The expected completion of the promt.\",\n",
    "                data_types=mlc.DataType.TEXT,\n",
    "                source=mlc.Source(\n",
    "                    file_set=\"jsonl-files\",\n",
    "                    extract=mlc.Extract(column=\"completion\"),\n",
    "                ),\n",
    "            ),\n",
    "            mlc.Field(\n",
    "                id=\"jsonl/task\",\n",
    "                name=\"task\",\n",
    "                description=(\n",
    "                    \"The machine learning task appearing as the name of the\"\n",
    "                    \" file.\"\n",
    "                ),\n",
    "                data_types=mlc.DataType.TEXT,\n",
    "                source=mlc.Source(\n",
    "                    file_set=\"jsonl-files\",\n",
    "                    extract=mlc.Extract(\n",
    "                        file_property=mlc._src.structure_graph.nodes.source.FileProperty.filename\n",
    "                    ),\n",
    "                    # Extract the field from a regex on the filename:\n",
    "                    transforms=[mlc.Transform(regex=\"^(.*)\\.jsonl$\")],\n",
    "                ),\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "]\n",
    "\n",
    "# Metadata contains information about the dataset.\n",
    "metadata = mlc.Metadata(\n",
    "    name=\"gpt-3\",\n",
    "    # Descriptions can contain plain text or markdown.\n",
    "    description=(\n",
    "        \"Recent work has demonstrated substantial gains on many NLP tasks and\"\n",
    "        \" benchmarks by pre-training on a large corpus of text followed by\"\n",
    "        \" fine-tuning on a specific task. While typically task-agnostic in\"\n",
    "        \" architecture, this method still requires task-specific fine-tuning\"\n",
    "        \" datasets of thousands or tens of thousands of examples. By contrast,\"\n",
    "        \" humans can generally perform a new language task from only a few\"\n",
    "        \" examples or from simple instructions \\u2013 something which current\"\n",
    "        \" NLP systems still largely struggle to do. Here we show that scaling\"\n",
    "        \" up language models greatly improves task-agnostic, few-shot\"\n",
    "        \" performance, sometimes even reaching competitiveness with prior\"\n",
    "        \" state-of-the-art fine-tuning approaches. Specifically, we train\"\n",
    "        \" GPT-3, an autoregressive language model with 175 billion parameters,\"\n",
    "        \" 10x more than any previous non-sparse language model, and test its\"\n",
    "        \" performance in the few-shot setting. For all tasks, GPT-3 is applied\"\n",
    "        \" without any gradient updates or fine-tuning, with tasks and few-shot\"\n",
    "        \" demonstrations specified purely via text interaction with the model.\"\n",
    "        \" GPT-3 achieves strong performance on many NLP datasets, including\"\n",
    "        \" translation, question-answering, and cloze tasks, as well as several\"\n",
    "        \" tasks that require on-the-fly reasoning or domain adaptation, such as\"\n",
    "        \" unscrambling words, using a novel word in a sentence, or performing\"\n",
    "        \" 3-digit arithmetic. At the same time, we also identify some datasets\"\n",
    "        \" where GPT-3's few-shot learning still struggles, as well as some\"\n",
    "        \" datasets where GPT-3 faces methodological issues related to training\"\n",
    "        \" on large web corpora. Finally, we find that GPT-3 can generate\"\n",
    "        \" samples of news articles which human evaluators have difficulty\"\n",
    "        \" distinguishing from articles written by humans. We discuss broader\"\n",
    "        \" societal impacts of this finding and of GPT-3 in general.\"\n",
    "    ),\n",
    "    cite_as=(\n",
    "        \"@article{brown2020language, title={Language Models are Few-Shot\"\n",
    "        \" Learners}, author={Tom B. Brown and Benjamin Mann and Nick Ryder and\"\n",
    "        \" Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind\"\n",
    "        \" Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and\"\n",
    "        \" Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom\"\n",
    "        \" Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and\"\n",
    "        \" Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and\"\n",
    "        \" Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and\"\n",
    "        \" Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford\"\n",
    "        \" and Ilya Sutskever and Dario Amodei}, year={2020},\"\n",
    "        \" eprint={2005.14165}, archivePrefix={arXiv}, primaryClass={cs.CL} }\"\n",
    "    ),\n",
    "    url=\"https://github.com/openai/gpt-3\",\n",
    "    distribution=distribution,\n",
    "    record_sets=record_sets,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the following 3 warning(s) during the validation:\n",
      "  -  [Metadata(gpt-3)] Property \"https://schema.org/datePublished\" is recommended, but does not exist.\n",
      "  -  [Metadata(gpt-3)] Property \"https://schema.org/license\" is recommended, but does not exist.\n",
      "  -  [Metadata(gpt-3)] Property \"https://schema.org/version\" is recommended, but does not exist.\n"
     ]
    }
   ],
   "source": [
    "print(metadata.issues.report())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"@context\": {\n",
      "    \"@language\": \"en\",\n",
      "    \"@vocab\": \"https://schema.org/\",\n",
      "    \"citeAs\": \"cr:citeAs\",\n",
      "    \"column\": \"cr:column\",\n",
      "    \"conformsTo\": \"dct:conformsTo\",\n",
      "    \"cr\": \"http://mlcommons.org/croissant/\",\n",
      "    \"rai\": \"http://mlcommons.org/croissant/RAI/\",\n",
      "    \"data\": {\n",
      "      \"@id\": \"cr:data\",\n",
      "      \"@type\": \"@json\"\n",
      "    },\n",
      "    \"dataType\": {\n",
      "      \"@id\": \"cr:dataType\",\n",
      "      \"@type\": \"@vocab\"\n",
      "    },\n",
      "    \"dct\": \"http://purl.org/dc/terms/\",\n",
      "    \"examples\": {\n",
      "      \"@id\": \"cr:examples\",\n",
      "      \"@type\": \"@json\"\n",
      "    },\n",
      "    \"extract\": \"cr:extract\",\n",
      "    \"field\": \"cr:field\",\n",
      "    \"fileProperty\": \"cr:fileProperty\",\n",
      "    \"fileObject\": \"cr:fileObject\",\n",
      "    \"fileSet\": \"cr:fileSet\",\n",
      "    \"format\": \"cr:format\",\n",
      "    \"includes\": \"cr:includes\",\n",
      "    \"isLiveDataset\": \"cr:isLiveDataset\",\n",
      "    \"jsonPath\": \"cr:jsonPath\",\n",
      "    \"key\": \"cr:key\",\n",
      "    \"md5\": \"cr:md5\",\n",
      "    \"parentField\": \"cr:parentField\",\n",
      "    \"path\": \"cr:path\",\n",
      "    \"recordSet\": \"cr:recordSet\",\n",
      "    \"references\": \"cr:references\",\n",
      "    \"regex\": \"cr:regex\",\n",
      "    \"repeated\": \"cr:repeated\",\n",
      "    \"replace\": \"cr:replace\",\n",
      "    \"sc\": \"https://schema.org/\",\n",
      "    \"separator\": \"cr:separator\",\n",
      "    \"source\": \"cr:source\",\n",
      "    \"subField\": \"cr:subField\",\n",
      "    \"transform\": \"cr:transform\"\n",
      "  },\n",
      "  \"@type\": \"sc:Dataset\",\n",
      "  \"name\": \"gpt-3\",\n",
      "  \"description\": \"Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions \\u2013 something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora. Finally, we find that GPT-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of GPT-3 in general.\",\n",
      "  \"conformsTo\": \"http://mlcommons.org/croissant/1.0\",\n",
      "  \"citeAs\": \"@article{brown2020language, title={Language Models are Few-Shot Learners}, author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei}, year={2020}, eprint={2005.14165}, archivePrefix={arXiv}, primaryClass={cs.CL} }\",\n",
      "  \"url\": \"https://github.com/openai/gpt-3\",\n",
      "  \"distribution\": [\n",
      "    {\n",
      "      \"@type\": \"cr:FileObject\",\n",
      "      \"@id\": \"github-repository\",\n",
      "      \"name\": \"github-repository\",\n",
      "      \"description\": \"OpenAI repository on GitHub.\",\n",
      "      \"contentUrl\": \"https://github.com/openai/gpt-3\",\n",
      "      \"encodingFormat\": \"git+https\",\n",
      "      \"sha256\": \"main\"\n",
      "    },\n",
      "    {\n",
      "      \"@type\": \"cr:FileSet\",\n",
      "      \"@id\": \"jsonl-files\",\n",
      "      \"name\": \"jsonl-files\",\n",
      "      \"description\": \"JSONL files are hosted on the GitHub repository.\",\n",
      "      \"containedIn\": {\n",
      "        \"@id\": \"github-repository\"\n",
      "      },\n",
      "      \"encodingFormat\": \"application/jsonlines\",\n",
      "      \"includes\": \"data/*.jsonl\"\n",
      "    }\n",
      "  ],\n",
      "  \"recordSet\": [\n",
      "    {\n",
      "      \"@type\": \"cr:RecordSet\",\n",
      "      \"@id\": \"jsonl\",\n",
      "      \"name\": \"jsonl\",\n",
      "      \"field\": [\n",
      "        {\n",
      "          \"@type\": \"cr:Field\",\n",
      "          \"@id\": \"jsonl/context\",\n",
      "          \"name\": \"context\",\n",
      "          \"dataType\": \"sc:Text\",\n",
      "          \"source\": {\n",
      "            \"fileSet\": {\n",
      "              \"@id\": \"jsonl-files\"\n",
      "            },\n",
      "            \"extract\": {\n",
      "              \"column\": \"context\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"@type\": \"cr:Field\",\n",
      "          \"@id\": \"jsonl/completion\",\n",
      "          \"name\": \"completion\",\n",
      "          \"description\": \"The expected completion of the promt.\",\n",
      "          \"dataType\": \"sc:Text\",\n",
      "          \"source\": {\n",
      "            \"fileSet\": {\n",
      "              \"@id\": \"jsonl-files\"\n",
      "            },\n",
      "            \"extract\": {\n",
      "              \"column\": \"completion\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"@type\": \"cr:Field\",\n",
      "          \"@id\": \"jsonl/task\",\n",
      "          \"name\": \"task\",\n",
      "          \"description\": \"The machine learning task appearing as the name of the file.\",\n",
      "          \"dataType\": \"sc:Text\",\n",
      "          \"source\": {\n",
      "            \"fileSet\": {\n",
      "              \"@id\": \"jsonl-files\"\n",
      "            },\n",
      "            \"extract\": {\n",
      "              \"fileProperty\": \"filename\"\n",
      "            },\n",
      "            \"transform\": {\n",
      "              \"regex\": \"^(.*)\\\\.jsonl$\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"croissant.json\", \"w\") as f:\n",
    "  content = metadata.to_json()\n",
    "  content = json.dumps(content, indent=2)\n",
    "  print(content)\n",
    "  f.write(content)\n",
    "  f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found the following 3 warning(s) during the validation:\n",
      "  -  [Metadata(gpt-3)] Property \"https://schema.org/datePublished\" is recommended, but does not exist.\n",
      "  -  [Metadata(gpt-3)] Property \"https://schema.org/license\" is recommended, but does not exist.\n",
      "  -  [Metadata(gpt-3)] Property \"https://schema.org/version\" is recommended, but does not exist.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'download_config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m builder \u001b[38;5;241m=\u001b[39m tfds\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39mdataset_builders\u001b[38;5;241m.\u001b[39mCroissantBuilder(\n\u001b[1;32m      2\u001b[0m     jsonld\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcroissant.json\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m     record_set_ids\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjsonl\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      4\u001b[0m     data_dir\u001b[38;5;241m=\u001b[39mdata_dir\n\u001b[1;32m      5\u001b[0m )\n\u001b[0;32m----> 6\u001b[0m builder\u001b[38;5;241m.\u001b[39mdownload_and_prepare(download_config\u001b[38;5;241m=\u001b[39m\u001b[43mdownload_config\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'download_config' is not defined"
     ]
    }
   ],
   "source": [
    "builder = tfds.core.dataset_builders.CroissantBuilder(\n",
    "    jsonld='croissant.json',\n",
    "    record_set_ids=['jsonl'],\n",
    "    data_dir=data_dir\n",
    ")\n",
    "builder.download_and_prepare(download_config=download_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found the following 3 warning(s) during the validation:\n",
      "  -  [Metadata(gpt-3)] Property \"https://schema.org/datePublished\" is recommended, but does not exist.\n",
      "  -  [Metadata(gpt-3)] Property \"https://schema.org/license\" is recommended, but does not exist.\n",
      "  -  [Metadata(gpt-3)] Property \"https://schema.org/version\" is recommended, but does not exist.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = mlc.Dataset(jsonld=\"croissant.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'jsonl/context': b'\\n\\nQ: What is 65360 plus 16204?\\n\\nA:', 'jsonl/completion': b'81564', 'jsonl/task': b'five_digit_addition'}\n",
      "{'jsonl/context': b'\\n\\nQ: What is 91169 plus 57223?\\n\\nA:', 'jsonl/completion': b'148392', 'jsonl/task': b'five_digit_addition'}\n",
      "{'jsonl/context': b'\\n\\nQ: What is 52888 plus 52240?\\n\\nA:', 'jsonl/completion': b'105128', 'jsonl/task': b'five_digit_addition'}\n",
      "{'jsonl/context': b'\\n\\nQ: What is 35742 plus 78660?\\n\\nA:', 'jsonl/completion': b'114402', 'jsonl/task': b'five_digit_addition'}\n",
      "{'jsonl/context': b'\\n\\nQ: What is 69074 plus 90431?\\n\\nA:', 'jsonl/completion': b'159505', 'jsonl/task': b'five_digit_addition'}\n",
      "{'jsonl/context': b'\\n\\nQ: What is 61530 plus 83035?\\n\\nA:', 'jsonl/completion': b'144565', 'jsonl/task': b'five_digit_addition'}\n",
      "{'jsonl/context': b'\\n\\nQ: What is 98901 plus 6004?\\n\\nA:', 'jsonl/completion': b'104905', 'jsonl/task': b'five_digit_addition'}\n",
      "{'jsonl/context': b'\\n\\nQ: What is 60097 plus 38097?\\n\\nA:', 'jsonl/completion': b'98194', 'jsonl/task': b'five_digit_addition'}\n",
      "{'jsonl/context': b'\\n\\nQ: What is 35779 plus 79717?\\n\\nA:', 'jsonl/completion': b'115496', 'jsonl/task': b'five_digit_addition'}\n",
      "{'jsonl/context': b'\\n\\nQ: What is 67255 plus 99168?\\n\\nA:', 'jsonl/completion': b'166423', 'jsonl/task': b'five_digit_addition'}\n",
      "{'jsonl/context': b'\\n\\nQ: What is 16566 plus 72378?\\n\\nA:', 'jsonl/completion': b'88944', 'jsonl/task': b'five_digit_addition'}\n",
      "{'jsonl/context': b'\\n\\nQ: What is 14127 plus 79804?\\n\\nA:', 'jsonl/completion': b'93931', 'jsonl/task': b'five_digit_addition'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "records = dataset.records(record_set=\"jsonl\")\n",
    "\n",
    "for i, record in enumerate(records):\n",
    "  print(record)\n",
    "  if i > 10:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
